{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.query_engine import SubQuestionQueryEngine\n",
    "from llama_index.callbacks import CallbackManager, LlamaDebugHandler\n",
    "from llama_index import ServiceContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the LlamaDebugHandler to print the trace of the sub questions\n",
    "# captured by the SUB_QUESTION callback event type\n",
    "llama_debug = LlamaDebugHandler(print_trace_on_end=True)\n",
    "callback_manager = CallbackManager([llama_debug])\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    callback_manager=callback_manager\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-11-25 15:13:28--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 75042 (73K) [text/plain]\n",
      "Saving to: ‘data/paul_graham/paul_graham_essay.txt’\n",
      "\n",
      "data/paul_graham/pa 100%[===================>]  73.28K  --.-KB/s    in 0.005s  \n",
      "\n",
      "2023-11-25 15:13:28 (14.3 MB/s) - ‘data/paul_graham/paul_graham_essay.txt’ saved [75042/75042]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p 'data/paul_graham/'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the LlamaDebugHandler to print the trace of the sub questions\n",
    "# captured by the SUB_QUESTION callback event type\n",
    "llama_debug = LlamaDebugHandler(print_trace_on_end=True)\n",
    "callback_manager = CallbackManager([llama_debug])\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    callback_manager=callback_manager\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Trace: index_construction\n",
      "    |_node_parsing ->  0.175273 seconds\n",
      "      |_chunking ->  0.170705 seconds\n",
      "    |_embedding ->  0.515095 seconds\n",
      "    |_embedding ->  0.515039 seconds\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "pg_essay = SimpleDirectoryReader(input_dir=\"./data/paul_graham/\").load_data()\n",
    "\n",
    "# build index and query engine\n",
    "vector_query_engine = VectorStoreIndex.from_documents(\n",
    "    pg_essay, use_async=True, service_context=service_context\n",
    ").as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine_tools = [\n",
    "    QueryEngineTool(\n",
    "        query_engine=vector_query_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"pg_essay\",\n",
    "            description=\"Paul Graham essay on What I Worked On\",\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "\n",
    "query_engine = SubQuestionQueryEngine.from_defaults(\n",
    "    query_engine_tools=query_engine_tools,\n",
    "    service_context=service_context,\n",
    "    use_async=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 3 sub questions.\n",
      "\u001b[1;3;38;2;237;90;200m[pg_essay] Q: What did Paul Graham work on before YC?\n",
      "\u001b[0m\u001b[1;3;38;2;90;149;237m[pg_essay] Q: What did Paul Graham work on during YC?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203m[pg_essay] Q: What did Paul Graham work on after YC?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203m[pg_essay] A: After YC, Paul Graham worked on Hacker News (HN) and wrote essays.\n",
      "\u001b[0m\u001b[1;3;38;2;90;149;237m[pg_essay] A: During his time at YC, Paul Graham worked on various projects. He initially intended to work on three things: hacking, writing essays, and working on YC. However, as YC grew and he became more excited about it, YC started to take up more of his attention. He also wrote all of YC's internal software in Arc. Eventually, his projects were reduced to two: writing essays and working on YC.\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200m[pg_essay] A: Before YC, Paul Graham worked on writing essays and developing the programming language Arc.\n",
      "\u001b[0m**********\n",
      "Trace: query\n",
      "    |_query ->  609.030634 seconds\n",
      "      |_llm ->  1.856309 seconds\n",
      "      |_sub_question ->  605.277604 seconds\n",
      "        |_query ->  605.277327 seconds\n",
      "          |_retrieve ->  0.179283 seconds\n",
      "            |_embedding ->  0.176705 seconds\n",
      "          |_synthesize ->  605.097905 seconds\n",
      "            |_templating ->  4e-05 seconds\n",
      "            |_llm ->  605.087839 seconds\n",
      "      |_sub_question ->  1.637167 seconds\n",
      "        |_query ->  1.63693 seconds\n",
      "          |_retrieve ->  0.147707 seconds\n",
      "            |_embedding ->  0.143141 seconds\n",
      "          |_synthesize ->  1.489059 seconds\n",
      "            |_templating ->  4e-05 seconds\n",
      "            |_llm ->  1.478879 seconds\n",
      "      |_sub_question ->  1.188229 seconds\n",
      "        |_query ->  1.187969 seconds\n",
      "          |_retrieve ->  0.162161 seconds\n",
      "            |_embedding ->  0.159565 seconds\n",
      "          |_synthesize ->  1.025653 seconds\n",
      "            |_templating ->  4.1e-05 seconds\n",
      "            |_llm ->  1.014461 seconds\n",
      "      |_synthesize ->  1.894692 seconds\n",
      "        |_templating ->  3e-05 seconds\n",
      "        |_llm ->  1.892193 seconds\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"How was Paul Grahams life different before, during, and after YC?\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapidly_fastapi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
